import librosa
import os
import numpy as np
import matplotlib.pyplot as plt


# ToDo: Rewrite all of the comments to fit the general scheme
# The code here has been generated by chatGPT. Hence, it needs to be cleaned up and adapted for our use case.
# ToDo: So far, all files receive the path as an input, maybe introduce option that takes a numpy array + sr as input
# ToDo: Find common names for all function: extract, compute -> ...
# ToDo: Write further comments


def extract_power_spectrum(file_path: str, plot: bool = False) -> np.ndarray:
    assert os.path.exists(file_path), "The given path does not exist! Please enter a valid path"
    # load the signal and compute the short-time fourier transform (STFT)
    audio, sampling_rate = librosa.load(file_path)
    stft = librosa.stft(audio)

    # calculate the power spectrum (dB)
    power = np.abs(stft) ** 2
    power_db = librosa.amplitude_to_db(power)

    # if the argument is provided, plot the power spectrum
    if plot:
        plt.figure(figsize=(12, 6))
        librosa.display.specshow(power_db, sr=sampling_rate, x_axis='time', y_axis='log')
        plt.colorbar(format='%+2.0f dB')
        plt.title('Power Spectrum')
        plt.show()

    return power_db


# ToDo: Ask supervisor or compare STFT and power spectrum, what is the difference?
def compute_stft(file_path: str, plot: bool = False) -> np.ndarray:
    assert os.path.exists(file_path), "The given path does not exist! Please enter a valid path"
    # load the signal and compute the short-time fourier transform (STFT)
    audio, sampling_rate = librosa.load(file_path)
    stft = librosa.stft(audio)
    stft_db = librosa.amplitude_to_db(np.abs(stft))

    if plot:
        # if the argument is provided, plot the power spectrum
        if plot:
            plt.figure(figsize=(12, 6))
            librosa.display.specshow(stft_db, sr=sampling_rate, x_axis='time', y_axis='log')
            plt.colorbar(format='%+2.0f dB')
            plt.title('STFT Spectrum')
            plt.show()

    return stft_db


# ToDo: Maybe change names to MFCCs (with s at the end)
# ToDo: Verify results
def extract_mfcc(file_path: str, highest_order: int = 0, plot: bool = False) -> np.ndarray:
    assert os.path.exists(file_path), "The given path does not exist! Please enter a valid path"
    assert highest_order > 0, "The provided order must be greater or equal to zero!"

    audio, sampling_rate = librosa.load(file_path)

    # compute the MFCC for different orders
    # ToDo: Simplify this entire section
    # ToDo: Maybe include color bar
    mfcc = librosa.feature.mfcc(y=audio, sr=sampling_rate)
    if highest_order > 0:
        higher_order_mfcc = []
        for order in range(1, highest_order):
            higher_order_mfcc.append(librosa.feature.delta(mfcc, order=order))

    if plot:
        fig, ax = plt.subplots((highest_order + 1), 1, figsize=(12, 6))
        librosa.display.specshow(mfcc, x_axis='time', ax=ax[0])
        ax[0].set(title='MFCC')
        if highest_order > 0:
            for idx in range(0, highest_order - 1):
                librosa.display.specshow(higher_order_mfcc[idx], x_axis='time', ax=ax[idx + 1])
                ax[idx + 1].set(title=f'MFCC {idx + 1}. Derivative')
        plt.tight_layout()
        plt.show()

    # ToDo: Needs to return also the derivatives
    return mfcc


def compute_zero_crossing_rate(file_path: str) -> np.ndarray:
    audio, sr = librosa.load(file_path)
    zcr = librosa.feature.zero_crossing_rate(audio)

    return zcr


# ToDo: Does not work this way, maybe filter signal beforehand
def find_boundaries(file_path: str, threshold: float = 0.01):
    audio, sr = librosa.load(file_path)
    zcr = librosa.feature.zero_crossing_rate(audio)
    # Convert the ZCR matrix to a 1-dimensional array
    zcr = np.squeeze(zcr)

    # Threshold for determining silence or non-silence
    threshold = 0.01

    # Find indices where ZCR is above the threshold
    non_silence_indices = np.where(zcr > threshold)[0]

    # Check if non-silence indices exist
    if non_silence_indices.size > 0:
        # Extract the starting and ending points
        start_index = non_silence_indices[0]
        end_index = non_silence_indices[-1]
        # Convert indices to time values
        start_time = start_index / float(sr)
        end_time = end_index / float(sr)
        # Print the start and end times
        print("Start time:", start_time)
        print("End time:", end_time)
    else:
        print("No non-silence segments found.")


if __name__ == '__main__':
    audio_file = 'torgo/F/F01/Session1/wav_arrayMic/0001.wav'
    # extract_power_spectrum = extract_power_spectrum(audio_file, True)
    # stft = compute_stft(audio_file, True)
    # extract_mfcc(audio_file, highest_order=1, plot=True)
    # compute_zero_crossing_rate(audio_file)
    find_boundaries(audio_file, threshold=0.1)

# ToDo: Read all of this again, implement the most important features
"""
Spectral features: Apart from the Fourier Transform, other spectral features like spectrograms, spectral contrast, 
spectral centroid, and spectral rolloff can be used to capture information about the distribution of spectral energy in 
the audio signal.

Linear Predictive Coding (LPC) coefficients: LPC analysis estimates the vocal tract filter parameters, which can be 
represented as LPC coefficients. These coefficients capture the formants and shape of the vocal tract and are useful 
for modeling speech production.

Perceptual Linear Prediction (PLP): PLP is a feature extraction technique that combines the advantages of LPC analysis 
and auditory modeling. It aims to model the human auditory system's perception of sound by incorporating frequency 
warping and critical band filtering.

Gammatone features: Gammatone filters mimic the filtering properties of the human auditory system. Gammatone features 
capture the energy distribution across different frequency bands and are particularly effective for capturing speech 
information.

Pitch or Fundamental Frequency (F0): F0 estimation provides information about the fundamental frequency of the speech 
signal. It is useful for tasks such as speaker diarization, prosody analysis, and intonation modeling.

Energy or Power: Energy or power features measure the overall energy content of the audio signal. They can be 
calculated as the squared magnitude of the signal or the logarithm of the squared magnitude.

These are just a few examples of common audio features used in ASR systems. Depending on the specific requirements and 
characteristics of your audio data, you may choose to use a combination of these features or explore additional 
techniques like wavelet transforms or deep learning-based feature representations.
"""
